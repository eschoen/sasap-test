---
title: "Data tidying"
author: "Erik Schoen"
date: "10/16/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

First, load packages.
```{r load packages, warning = F, message = F}
library(dplyr)
library(tidyr)
```

Then read in catch data from [Mike Byerly. Alaska commercial salmon catches by management region (1886- 1997). Gulf of Alaska Data Portal](https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1)

```{r read in data}
catch_df <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1", method = "libcurl"),
                    stringsAsFactors = FALSE)
head(catch_df)
```

(Using backticks denotes text rendered to look like code)
`select` the columns we need for the analysis
`gather` to reshape from wide to long format
`rename` to indicate units of catch

```{r}
catch_clean <- catch_df %>% 
  select(Region, Year, Chinook, Sockeye, Pink, Chum) %>% 
  gather(key = "Species", value = "Catch", -Region, -Year) %>% 
  rename(Catch_1000s = Catch)

head(catch_clean)

```

Find a typo preventing Catch_1000s from being coerced to numeric
```{r}
test <- as.numeric(catch_clean$Catch_1000s)
i <- which(is.na(test) == T)
print(i)
catch_clean[i, ]
```

`mutate` to fix a typo, convert catch_1000s to numeric, and create a new catch column in numbers of fish

```{r}
catch_clean_mutated <- catch_clean %>% 
  mutate(Catch_1000s = ifelse(Catch_1000s == "I", 1, Catch_1000s)) %>%
  mutate(Catch_1000s = as.numeric(Catch_1000s)) %>%
  mutate(Catch = Catch_1000s * 1000) %>%
  select(-Catch_1000s)

tail(catch_clean_mutated)
```

split using `group_by`
apply and combine using `summarize`

```{r}
catch_summarized <- catch_clean_mutated %>%
  group_by(Region, Year) %>%
  summarize(mean_catch = mean(Catch),
            sd_catch = sd(Catch),
            n_obs = n())

head(catch_summarized)
```


```{r}
catch_chinook <- catch_clean_mutated %>%
  filter(Species == "Chinook") %>%
  group_by(Region) %>%
  summarize(meanCatch = mean(Catch))

head(catch_chinook)
```

# Read in regions data table
```{r}
region_defs <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.303.1", method = "libcurl"),
                        stringsAsFactors = FALSE)
head(region_defs)
```

```{r}
region_defs <- region_defs %>% 
  select(Region = code, mgmtArea)
head(region_defs)
```

Best practices for joins:
+ Always write to a new data frame, and then check if the number of rows in the new table matches the left table.
+ Put both tables into the parentheses to make it more clear which are the left
and right tables (don't use a pipe).
+ Check for NAs or duplicates in your primary keys
```{r}
catch_joined <- left_join(catch_clean_mutated, region_defs, by = "Region") 
head(catch_joined)
# check if any regions didn't join
i <- which(is.na(catch_joined$mgmtArea))
nrow(i)
# good, no regions are NA
```

Make some date data in a non-ideal format  
Then `separate` it into separate columns
```{r}
dates_df <- data.frame(date = c("5/24/1930",
                                "5/25/1930",
                                "5/26/1930",
                                "5/27/1930",
                                "5/28/1930"),
                       stringsAsFactors = FALSE)

dates_df <- dates_df %>% 
  separate(date, c("month", "day", "year"), "/", remove = F)

dates_iso <- dates_df %>% 
  unite(col = date_iso, year, month, day, sep = "-")
head(dates_iso)
```



